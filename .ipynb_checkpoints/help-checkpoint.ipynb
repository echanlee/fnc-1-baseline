{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "help ",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-yOuuSQ00a4D"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn import feature_extraction\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from feature_engineering import initialize_test, refuting_features, polarity_features, hand_features, gen_or_load_feats\n",
        "from feature_engineering import word_overlap_features\n",
        "from dataset import DataSet\n",
        "from generate_test_splits import kfold_split, get_stances_for_folds\n",
        "from score import report_score, LABELS, score_submission\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from keras.models import Sequential\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.layers import Dense, Embedding, Dropout, Flatten\n",
        "from keras import regularizers\n",
        "\n",
        "from system import parse_params, check_version"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ssbM2w-vHrr6",
        "outputId": "08fa68cb-4fd6-45c7-e6f8-2b1e221400b2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = feature_extraction.text.ENGLISH_STOP_WORDS\n",
        "BATCH_SIZE = 128"
      ],
      "metadata": {
        "id": "6QGkIqkt5U1Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_tfidf(stances, dataset):\n",
        "    heads, bodies = [],[]\n",
        "\n",
        "    for stance in stances:\n",
        "        heads.append(stance['Headline'])\n",
        "        bodies.append(dataset.articles[stance['Body ID']])\n",
        "    bow_vectorizer = CountVectorizer(max_features=5000, stop_words=stop_words)\n",
        "    bow = bow_vectorizer.fit_transform(heads + bodies)  # Train set only\n",
        "\n",
        "    tfreq_vectorizer = TfidfTransformer(use_idf=False).fit(bow)\n",
        "    tfreq = tfreq_vectorizer.transform(bow).toarray()  # Train set only\n",
        "\n",
        "    tfidf_vectorizer = TfidfVectorizer(max_features=5000, stop_words=stop_words).\\\n",
        "        fit(heads + bodies ) \n",
        "    return bow_vectorizer, tfreq_vectorizer, tfreq, tfidf_vectorizer"
      ],
      "metadata": {
        "id": "Jj5FszKS5Xw5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d = DataSet()\n",
        "bow_vectorizer, tfreq_vectorizer, tfreq, tfidf_vectorizer = generate_tfidf(d.stances, d)\n",
        "folds,hold_out = kfold_split(d,n_folds=10)\n",
        "fold_stances, hold_out_stances = get_stances_for_folds(d,folds,hold_out)\n",
        "\n",
        "# Load the competition dataset\n",
        "competition_dataset = DataSet(\"competition_test\")\n",
        "X_competition, y_competition = initialize_test(competition_dataset.stances, competition_dataset, bow_vectorizer, tfreq_vectorizer, tfidf_vectorizer)\n",
        "\n",
        "Xs = dict()\n",
        "ys = dict()\n",
        "\n",
        "# Load/Precompute all features now\n",
        "X_holdout,y_holdout = initialize_test(hold_out_stances,d, bow_vectorizer, tfreq_vectorizer, tfidf_vectorizer)\n",
        "for fold in fold_stances:\n",
        "    Xs[fold],ys[fold] = initialize_test(fold_stances[fold],d, bow_vectorizer, tfreq_vectorizer, tfidf_vectorizer)\n",
        "\n",
        "\n",
        "best_score = 0\n",
        "best_fold = None"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPItYkrC5eQ-",
        "outputId": "dcec175d-9efa-4b43-80cd-c5d3fa773bbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading dataset\n",
            "Total stances: 49972\n",
            "Total bodies: 1683\n",
            "Reading dataset\n",
            "Total stances: 25413\n",
            "Total bodies: 904\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(num_words=115550, filters='!\"#$%&()*+,-./:;<=>@[\\\\]^_`{|}~\\t\\n') \n",
        "tokenizer.fit_on_texts(list(d.articles.values()) + list(competition_dataset.articles.values()))"
      ],
      "metadata": {
        "id": "4O1YDw917WDL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for fold in fold_stances:\n",
        "        ids = list(range(len(folds)))\n",
        "        del ids[fold]\n",
        "        print(\"training\")\n",
        "        X_train = np.vstack(tuple([Xs[i] for i in ids]))\n",
        "        y_train = np.hstack(tuple([ys[i] for i in ids]))\n",
        "\n",
        "        X_test = Xs[fold]\n",
        "        y_test = ys[fold]\n",
        "        \n",
        "        # clf = Sequential()\n",
        "        # clf.add(Embedding(input_dim=len(tokenizer.word_index)+1,\n",
        "        #                   output_dim=100,trainable=False, name='word_embedding_layer', \n",
        "        #                   mask_zero=True))\n",
        "        # clf.add(Flatten())\n",
        "        # clf.add(Dense(32, activation='relu', kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),\n",
        "        #     bias_regularizer=regularizers.l2(1e-4), name='hidden_layer',input_shape =(BATCH_SIZE,) ))\n",
        "        # clf.add(Dropout(rate=0.20, name='dropout_1')) \n",
        "\n",
        "        # clf.add(Dense(2, activation='softmax', name='output_layer'))\n",
        "\n",
        "        # clf.compile(loss='binary_crossentropy', optimizer='adam',\n",
        "        #     metrics=['accuracy'])\n",
        "        \n",
        "        # clf.fit(X_train, y_train,\n",
        "        # batch_size=BATCH_SIZE,\n",
        "        # epochs=12,)\n",
        "\n",
        "        # predicted = [LABELS[int(a)] for a in clf.predict(X_test)]\n",
        "        # actual = [LABELS[int(a)] for a in y_test]\n",
        "\n",
        "        # fold_score, _ = score_submission(actual, predicted)\n",
        "        # max_fold_score, _ = score_submission(actual, actual)\n",
        "\n",
        "        # score = fold_score/max_fold_score\n",
        "\n",
        "        # print(\"Score for fold \"+ str(fold) + \" was - \" + str(score))\n",
        "        # if score > best_score:\n",
        "        #     best_score = score\n",
        "        #     best_fold = clf\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I5iFwzoE7Mhj",
        "outputId": "e89b5899-2c82-47de-9a7a-b92ef421e5e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -R \"drive/MyDrive/4B/MSCI 598/fnc-1-baseline/features\" ."
      ],
      "metadata": {
        "id": "KiSnEqTF53vQ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d = DataSet()\n",
        "folds,hold_out = kfold_split(d,n_folds=10)\n",
        "fold_stances, hold_out_stances = get_stances_for_folds(d,folds,hold_out)\n",
        "\n",
        "# Load the competition dataset\n",
        "competition_dataset = DataSet(\"competition_test\")\n",
        "X_competition, y_competition = generate_features(competition_dataset.stances, competition_dataset, \"competition\")\n",
        "\n",
        "Xs = dict()\n",
        "ys = dict()\n",
        "\n",
        "# Load/Precompute all features now\n",
        "X_holdout,y_holdout = generate_features(hold_out_stances,d,\"holdout\")\n",
        "for fold in fold_stances:\n",
        "    Xs[fold],ys[fold] = generate_features(fold_stances[fold],d,str(fold))\n",
        "\n",
        "\n",
        "best_score = 0\n",
        "best_fold = None\n",
        "\n",
        "\n",
        "# Classifier for each fold\n",
        "for fold in fold_stances:\n",
        "    ids = list(range(len(folds)))\n",
        "    del ids[fold]\n",
        "\n",
        "    X_train = np.vstack(tuple([Xs[i] for i in ids]))\n",
        "    y_train = np.hstack(tuple([ys[i] for i in ids]))\n",
        "\n",
        "    X_test = Xs[fold]\n",
        "    y_test = ys[fold]\n",
        "\n",
        "    clf = GradientBoostingClassifier(n_estimators=200, random_state=14128, verbose=True)\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    predicted = [LABELS[int(a)] for a in clf.predict(X_test)]\n",
        "    actual = [LABELS[int(a)] for a in y_test]\n",
        "\n",
        "    fold_score, _ = score_submission(actual, predicted)\n",
        "    max_fold_score, _ = score_submission(actual, actual)\n",
        "\n",
        "    score = fold_score/max_fold_score\n",
        "\n",
        "    print(\"Score for fold \"+ str(fold) + \" was - \" + str(score))\n",
        "    if score > best_score:\n",
        "        best_score = score\n",
        "        best_fold = clf\n",
        "\n",
        "\n",
        "\n",
        "#Run on Holdout set and report the final score on the holdout set\n",
        "predicted = [LABELS[int(a)] for a in best_fold.predict(X_holdout)]\n",
        "actual = [LABELS[int(a)] for a in y_holdout]\n",
        "\n",
        "print(\"Scores on the dev set\")\n",
        "report_score(actual,predicted)\n",
        "print(\"\")\n",
        "print(\"\")\n",
        "\n",
        "#Run on competition dataset\n",
        "predicted = [LABELS[int(a)] for a in best_fold.predict(X_competition)]\n",
        "actual = [LABELS[int(a)] for a in y_competition]\n",
        "\n",
        "print(\"Scores on the test set\")\n",
        "report_score(actual,predicted)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_uOqpoPHHgrG",
        "outputId": "f74661a0-5819-4190-dd69-655bb221201b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading dataset\n",
            "Total stances: 49972\n",
            "Total bodies: 1683\n",
            "Reading dataset\n",
            "Total stances: 25413\n",
            "Total bodies: 904\n",
            "      Iter       Train Loss   Remaining Time \n",
            "         1           0.6946           53.54s\n",
            "         2           0.6307           52.69s\n",
            "         3           0.5834           51.85s\n",
            "         4           0.5463           51.89s\n",
            "         5           0.5175           51.37s\n",
            "         6           0.4928           51.05s\n",
            "         7           0.4729           50.85s\n",
            "         8           0.4560           50.71s\n",
            "         9           0.4427           50.45s\n",
            "        10           0.4299           50.12s\n",
            "        20           0.3696           47.02s\n",
            "        30           0.3488           44.18s\n",
            "        40           0.3378           41.71s\n",
            "        50           0.3311           39.04s\n",
            "        60           0.3258           36.49s\n",
            "        70           0.3219           33.83s\n",
            "        80           0.3186           31.19s\n",
            "        90           0.3158           28.54s\n",
            "       100           0.3133           25.91s\n",
            "       200           0.2943            0.00s\n",
            "Score for fold 6 was - 0.7700373455903476\n",
            "      Iter       Train Loss   Remaining Time \n",
            "         1           0.6965           50.20s\n",
            "         2           0.6318           50.10s\n",
            "         3           0.5842           49.93s\n",
            "         4           0.5468           50.02s\n",
            "         5           0.5170           49.71s\n",
            "         6           0.4936           49.28s\n",
            "         7           0.4729           49.01s\n",
            "         8           0.4560           49.04s\n",
            "         9           0.4420           48.82s\n",
            "        10           0.4303           48.51s\n",
            "        20           0.3689           45.73s\n",
            "        30           0.3484           42.97s\n",
            "        40           0.3373           40.46s\n",
            "        50           0.3305           37.97s\n",
            "        60           0.3254           35.54s\n",
            "        70           0.3216           32.98s\n",
            "        80           0.3183           30.47s\n",
            "        90           0.3156           28.01s\n",
            "       100           0.3132           25.51s\n",
            "       200           0.2942            0.00s\n",
            "Score for fold 0 was - 0.7966413336602108\n",
            "      Iter       Train Loss   Remaining Time \n",
            "         1           0.6886           53.17s\n",
            "         2           0.6246           53.28s\n",
            "         3           0.5774           52.45s\n",
            "         4           0.5407           51.67s\n",
            "         5           0.5115           51.41s\n",
            "         6           0.4884           51.25s\n",
            "         7           0.4682           51.01s\n",
            "         8           0.4522           50.86s\n",
            "         9           0.4380           50.65s\n",
            "        10           0.4261           50.28s\n",
            "        20           0.3664           47.14s\n",
            "        30           0.3438           44.41s\n",
            "        40           0.3330           41.82s\n",
            "        50           0.3262           39.25s\n",
            "        60           0.3204           36.65s\n",
            "        70           0.3163           34.07s\n",
            "        80           0.3129           31.49s\n",
            "        90           0.3100           28.88s\n",
            "       100           0.3076           26.26s\n",
            "       200           0.2891            0.00s\n",
            "Score for fold 7 was - 0.8056851930420026\n",
            "      Iter       Train Loss   Remaining Time \n",
            "         1           0.6805           51.44s\n",
            "         2           0.6166           51.67s\n",
            "         3           0.5699           52.02s\n",
            "         4           0.5337           51.88s\n",
            "         5           0.5051           51.52s\n",
            "         6           0.4814           51.27s\n",
            "         7           0.4621           51.24s\n",
            "         8           0.4456           50.77s\n",
            "         9           0.4319           50.49s\n",
            "        10           0.4204           50.20s\n",
            "        20           0.3613           47.20s\n",
            "        30           0.3395           44.59s\n",
            "        40           0.3293           41.96s\n",
            "        50           0.3223           39.38s\n",
            "        60           0.3172           36.76s\n",
            "        70           0.3131           34.17s\n",
            "        80           0.3096           31.54s\n",
            "        90           0.3068           28.94s\n",
            "       100           0.3043           26.34s\n",
            "       200           0.2863            0.00s\n",
            "Score for fold 5 was - 0.7652430044182621\n",
            "      Iter       Train Loss   Remaining Time \n",
            "         1           0.6893           55.41s\n",
            "         2           0.6261           53.83s\n",
            "         3           0.5791           52.63s\n",
            "         4           0.5429           52.50s\n",
            "         5           0.5144           52.04s\n",
            "         6           0.4904           51.80s\n",
            "         7           0.4712           51.30s\n",
            "         8           0.4550           51.20s\n",
            "         9           0.4414           50.77s\n",
            "        10           0.4291           50.40s\n",
            "        20           0.3692           47.33s\n",
            "        30           0.3476           44.63s\n",
            "        40           0.3369           41.83s\n",
            "        50           0.3301           39.21s\n",
            "        60           0.3253           36.65s\n",
            "        70           0.3212           34.04s\n",
            "        80           0.3177           31.36s\n",
            "        90           0.3150           28.74s\n",
            "       100           0.3125           26.13s\n",
            "       200           0.2937            0.00s\n",
            "Score for fold 2 was - 0.8163710380924687\n",
            "      Iter       Train Loss   Remaining Time \n",
            "         1           0.6998           49.31s\n",
            "         2           0.6357           49.12s\n",
            "         3           0.5886           49.06s\n",
            "         4           0.5513           49.70s\n",
            "         5           0.5217           49.41s\n",
            "         6           0.4977           49.00s\n",
            "         7           0.4777           48.81s\n",
            "         8           0.4614           48.69s\n",
            "         9           0.4471           48.46s\n",
            "        10           0.4347           48.17s\n",
            "        20           0.3745           45.09s\n",
            "        30           0.3531           42.63s\n",
            "        40           0.3425           40.70s\n",
            "        50           0.3356           38.33s\n",
            "        60           0.3303           35.80s\n",
            "        70           0.3260           33.19s\n",
            "        80           0.3223           30.66s\n",
            "        90           0.3194           28.18s\n",
            "       100           0.3168           25.64s\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-a738fc90f256>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGradientBoostingClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m14128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mLABELS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m    594\u001b[0m             \u001b[0msample_weight_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m             \u001b[0mbegin_at_stage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m             \u001b[0mmonitor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    597\u001b[0m         )\n\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[0;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001b[0m\n\u001b[1;32m    670\u001b[0m                 \u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m                 \u001b[0mX_csc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m                 \u001b[0mX_csr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m             )\n\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36m_fit_stage\u001b[0;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m             residual = loss.negative_gradient(\n\u001b[0;32m--> 223\u001b[0;31m                 \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_predictions_copy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m             )\n\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_gb_losses.py\u001b[0m in \u001b[0;36mnegative_gradient\u001b[0;34m(self, y, raw_predictions, k, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m         \"\"\"\n\u001b[1;32m    822\u001b[0m         return y - np.nan_to_num(\n\u001b[0;32m--> 823\u001b[0;31m             \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_predictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlogsumexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    824\u001b[0m         )\n\u001b[1;32m    825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/special/_logsumexp.py\u001b[0m in \u001b[0;36mlogsumexp\u001b[0;34m(a, axis, b, keepdims, return_sign)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;31m# suppress warnings about log of zero\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdivide\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_sign\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0msgn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msum\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36msum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2259\u001b[0m     return _wrapreduction(a, np.add, 'sum', axis, dtype, out, keepdims=keepdims,\n\u001b[0;32m-> 2260\u001b[0;31m                           initial=initial, where=where)\n\u001b[0m\u001b[1;32m   2261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_features(stances,dataset,name):\n",
        "    h, b, y = [],[],[]\n",
        "\n",
        "    for stance in stances:\n",
        "        y.append(LABELS.index(stance['Stance']))\n",
        "        h.append(stance['Headline'])\n",
        "        b.append(dataset.articles[stance['Body ID']])\n",
        "\n",
        "    X_overlap = gen_or_load_feats(word_overlap_features, h, b, \"features/overlap.\"+name+\".npy\")\n",
        "    X_refuting = gen_or_load_feats(refuting_features, h, b, \"features/refuting.\"+name+\".npy\")\n",
        "    X_polarity = gen_or_load_feats(polarity_features, h, b, \"features/polarity.\"+name+\".npy\")\n",
        "    X_hand = gen_or_load_feats(hand_features, h, b, \"features/hand.\"+name+\".npy\")\n",
        "\n",
        "    X = np.c_[X_hand, X_polarity, X_refuting, X_overlap]\n",
        "    return X,y\n"
      ],
      "metadata": {
        "id": "-bTKw1clHWwQ"
      },
      "execution_count": 2,
      "outputs": []
    }
  ]
}